{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EEG Feature Extraction.ipynb","provenance":[],"mount_file_id":"1MBF7G6cEtClE7cTFqa7J9iMZPo8cDUtS","authorship_tag":"ABX9TyNxolltxJtD5gjMItzNcPPF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WixtMeQsck25","colab_type":"code","outputId":"ab1d8469-d36b-4a38-d7c0-777d866e2472","executionInfo":{"status":"error","timestamp":1591417794490,"user_tz":-330,"elapsed":2093,"user":{"displayName":"KALAIVAANI.N 17ITR044","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64","userId":"06629915513144874112"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"source":["import numpy as np\n","import pyedflib\n","from matplotlib import pyplot as plt\n","from nitime import utils\n","from nitime import algorithms as alg\n","from nitime.timeseries import TimeSeries\n","from nitime.viz import plot_tseries\n","import csv\n","import pywt\n","import scipy.stats as sp\n","from spectrum import *\n","from os import listdir\n","from os.path import isfile, join"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2bbbfdffe3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyedflib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnitime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnitime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malgorithms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyedflib'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"BMUxL35fdDaU","colab_type":"code","outputId":"32d81c38-dc68-4be3-b15d-981fa410d698","executionInfo":{"status":"ok","timestamp":1591527510390,"user_tz":-330,"elapsed":7502,"user":{"displayName":"KALAIVAANI.N 17ITR044","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64","userId":"06629915513144874112"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!pip install pyedflib"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyedflib in /usr/local/lib/python3.6/dist-packages (0.1.17)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyedflib) (1.18.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pOetOATcdPhC","colab_type":"code","outputId":"756f946e-6e51-421d-b444-1fa1b43bc0fb","executionInfo":{"status":"ok","timestamp":1591527523224,"user_tz":-330,"elapsed":14605,"user":{"displayName":"KALAIVAANI.N 17ITR044","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64","userId":"06629915513144874112"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["!pip install nitime"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting nitime\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/28/3cb014175d93fd01f2b13250afcace3c19e5abfe36790943f3cc6519a8e2/nitime-0.8.1.tar.gz (9.0MB)\n","\u001b[K     |████████████████████████████████| 9.1MB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.18.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from nitime) (0.29.19)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nitime) (3.2.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from nitime) (2.4)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from nitime) (3.0.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.4.7)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->nitime) (4.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->nitime) (1.12.0)\n","Building wheels for collected packages: nitime\n","  Building wheel for nitime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nitime: filename=nitime-0.8.1-cp36-cp36m-linux_x86_64.whl size=4038230 sha256=c616361cc861cf5641807ef5f8e9f1adeeff42bf99ca744ff3bae4a84a47a59d\n","  Stored in directory: /root/.cache/pip/wheels/74/02/c5/677c895b41dcaf4fd7c4ff436fbdf8a5d846ed90a0a3276073\n","Successfully built nitime\n","Installing collected packages: nitime\n","Successfully installed nitime-0.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vhIYq_7Gdguu","colab_type":"code","outputId":"3c6dab10-be7e-4e38-f429-8f67a7016e73","executionInfo":{"status":"ok","timestamp":1591527531623,"user_tz":-330,"elapsed":8789,"user":{"displayName":"KALAIVAANI.N 17ITR044","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64","userId":"06629915513144874112"}},"colab":{"base_uri":"https://localhost:8080/","height":319}},"source":["!pip install spectrum"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting spectrum\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/40/1923c4ab434024f1eb9b9ab3b2b0693ddacb21ace92ea280461b37605c0e/spectrum-0.7.6.tar.gz (227kB)\n","\r\u001b[K     |█▍                              | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectrum) (1.18.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spectrum) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from spectrum) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->spectrum) (0.10.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->spectrum) (1.12.0)\n","Building wheels for collected packages: spectrum\n","  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spectrum: filename=spectrum-0.7.6-cp36-cp36m-linux_x86_64.whl size=234246 sha256=4e5e25168e0f7519a2b29ebf4c0b6159da63694d9f6633997ba59ad33dae7717\n","  Stored in directory: /root/.cache/pip/wheels/7b/a1/1f/16e3bd0418dc16201a4f2e696ab00de3e3c95549cba7df5d13\n","Successfully built spectrum\n","Installing collected packages: spectrum\n","Successfully installed spectrum-0.7.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z5D31DSudxWH","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pyedflib\n","from matplotlib import pyplot as plt\n","from nitime import utils\n","from nitime import algorithms as alg\n","from nitime.timeseries import TimeSeries\n","from nitime.viz import plot_tseries\n","import csv\n","import pywt\n","import scipy.stats as sp\n","from spectrum import *\n","from os import listdir\n","from os.path import isfile, join"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsPa--1ud2DL","colab_type":"code","colab":{}},"source":["names = ['Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n","          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n","          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Variance','Mean of Vertex to Vertex Slope','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower',\n","          'Autro Regressive Mode Order 3 Coefficients for each channel ->']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYTWyqVkeATA","colab_type":"code","colab":{}},"source":["def hjorth(input):                                             # function for hjorth \n","    realinput = input\n","    hjorth_activity = np.zeros(len(realinput))\n","    hjorth_mobility = np.zeros(len(realinput))\n","    hjorth_diffmobility = np.zeros(len(realinput))\n","    hjorth_complexity = np.zeros(len(realinput))\n","    diff_input = np.diff(realinput)\n","    diff_diffinput = np.diff(diff_input)\n","    k = 0\n","    for j in realinput:\n","        hjorth_activity[k] = np.var(j)\n","        hjorth_mobility[k] = np.sqrt(np.var(diff_input[k])/hjorth_activity[k])\n","        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput[k])/np.var(diff_input[k]))\n","        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n","        k = k+1\n","    return np.sum(hjorth_activity)/14, np.sum(hjorth_mobility)/14, np.sum(hjorth_complexity)/14 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8WEpZqheC5y","colab_type":"code","colab":{}},"source":["def my_kurtosis(a):\n","    b = a # Extracting the data from the 14 channels\n","    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n","    k = 0; # For counting the current row no.\n","    for i in b:\n","        mean_i = np.mean(i) # Saving the mean of array i\n","        std_i = np.std(i) # Saving the standard deviation of array i\n","        t = 0.0\n","        for j in i:\n","            t += (pow((j-mean_i)/std_i,4)-3)\n","        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n","        output[k] = kurtosis_i # Saving the kurtosis in the array created\n","        k +=1 # Updating the current row no.\n","    return np.sum(output)/14\n","\n","##----------------------------------------- End Kurtosis Function ----------------------------##\n","\n","\n","##------------------------------------- Begin 2ndDiffMean(Absolute difference) Function ------##\n","##-------------------------- [ Input: 2D array (row: Channels, column: Data)] --------------- ##\n","##-------------------  -- [ Output: 1D array (2ndDiffMean values for each channel)] ----------##\n","\n","def secDiffMean(a):\n","    b = a # Extracting the data of the 14 channels\n","    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n","    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n","    k = 0; # For counting the current row no.\n","    for i in b:\n","       \tt = 0.0\n","        for j in range(len(i)-1):\n","            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n","        for j in range(len(i)-2):\n","            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n","        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n","        k +=1 # Updating the current row no.\n","    return np.sum(output)/14\n","\n","##------------------------------------- End 2ndDiffMean Function----- -------------------------##\n","\n","\n","##------------------------------------- Begin 2ndDiffMax Function(Absolute difference) --------##\n","##-------------------------- [ Input: 2D array (row: Channels, column: Data)] -----------------##\n","##--------------------- [ Output: 1D array (2ndDiffMax values for each channel)] --------------##\n","\n","def secDiffMax(a):\n","    b = a # Extracting the data from the 14 channels\n","    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n","    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n","    k = 0; # For counting the current row no.\n","    t = 0.0\n","    for i in b:\n","        for j in range(len(i)-1):\n","            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n","        t = temp1[1] - temp1[0]\n","        for j in range(len(i)-2):\n","            if abs(temp1[j+1]-temp1[j]) > t :\n","            \tt = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n","\n","        output[k] = t # Storing the 2nd Diff Max for channel k\n","        k +=1 # Updating the current row no.\n","    return np.sum(output)/14\n","\n","\n","\n","def wrapper1(a):\n","    kurtosis =  my_kurtosis(a)\n","    sec_diff_mean = secDiffMean(a)\n","    sec_diff_max  = secDiffMax(a)\n","    return kurtosis,sec_diff_mean,sec_diff_max"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjZ5FLv_eabz","colab_type":"code","colab":{}},"source":["def coeff_var(a):\n","    b = a #Extracting the data from the 14 channels\n","    output = np.zeros(len(b)) #Initializing the output array with zeros\n","    k = 0; #For counting the current row no.\n","    for i in b:\n","        mean_i = np.mean(i) #Saving the mean of array i\n","        std_i = np.std(i) #Saving the standard deviation of array i\n","        output[k] = std_i/mean_i #computing coefficient of variation\n","        k=k+1\n","    return np.sum(output)/14"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQ_Q5xYpgpmR","colab_type":"code","colab":{}},"source":["def skewness(arr):\n","    data = arr \n","    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n","    index = 0; #current cell position in the output array\n","   \n","    for i in data:\n","        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n","        index+=1 #updating the cell position\n","    return np.sum(skew_array)/14\n","\n","\n","def first_diff_mean(arr):\n","    data = arr \n","    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n","    index = 0; #current cell position in the output array\n","   \n","    for i in data:\n","        sum=0.0#initializing the sum at the start of each iteration\n","        for j in range(len(i)-1):\n","            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n","           \n","        diff_mean_array[index]=sum/(len(i)-1)\n","        index+=1 #updating the cell position\n","    return np.sum(diff_mean_array)/14\n","\n","\n","def first_diff_max(arr):\n","    data = arr \n","    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n","    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n","    index = 0; #current cell position in the output array\n","   \n","    for i in data:\n","        max=0.0#initializing at the start of each iteration\n","        for j in range(len(i)-1):\n","            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n","            if first_diff[j]>max: \n","                max=first_diff[j] # finding the maximum of the first differences\n","        diff_max_array[index]=max\n","        index+=1 #updating the cell position\n","    return np.sum(diff_max_array)/14\n","\n","\n","def wrapper2(arr):\n","    skew   = skewness(arr)\n","    fdmean = first_diff_mean(arr)\n","    fdmax  = first_diff_max(arr)\n","    return skew,fdmean,fdmax"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HE9NPTF3gz2u","colab_type":"code","colab":{}},"source":["def wavelet_features(epoch):\n","    cA_values = []\n","    cD_values = []\n","    cA_mean = []\n","    cA_std = []\n","    cA_Energy =[]\n","    cD_mean = []\n","    cD_std = []\n","    cD_Energy = []\n","    Entropy_D = []\n","    Entropy_A = []\n","    for i in range(14):\n","        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n","        cA_values.append(cA)\n","        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n","    for x in range(14):   \n","        cA_mean.append(np.mean(cA_values[x]))\n","        cA_std.append(np.std(cA_values[x]))\n","        cA_Energy.append(np.sum(np.square(cA_values[x])))\n","        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n","        cD_std.append(np.std(cD_values[x]))\n","        cD_Energy.append(np.sum(np.square(cD_values[x])))\n","        Entropy_D.append(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x]))))\n","        Entropy_A.append(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))\n","    return np.sum(cA_mean)/14,np.sum(cA_std)/14,np.sum(cD_mean)/14,np.sum(cD_std)/14,np.sum(cA_Energy)/14,np.sum(cD_Energy)/14,np.sum(Entropy_A)/14,np.sum(Entropy_D)/14"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXVQ0sgPhDti","colab_type":"code","colab":{}},"source":["import heapq\n","\n","from scipy.signal import argrelextrema\n","\n","def first_diff(i):\n","    b=i\n","    \n","    \n","    out = np.zeros(len(b))\n","    \n","    for j in range(len(i)):\n","        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n","        \n","        j=j+1\n","        c=out[1:len(out)]\n","    return c\n","\n","#first_diff(s)\n","\n","def slope_mean(p):\n","    b = p #Extracting the data from the 14 channels\n","    output = np.zeros(len(b)) #Initializing the output array with zeros\n","    res = np.zeros(len(b)-1)\n","    \n","    k = 0; #For counting the current row no.\n","    for i in b:\n","        x=i\n","        amp_max = i[argrelextrema(x, np.greater)[0]]\n","        t_max = argrelextrema(x, np.greater)[0]\n","        amp_min = i[argrelextrema(x, np.less)[0]]\n","        t_min = argrelextrema(x, np.less)[0]\n","        t = np.concatenate((t_max,t_min),axis=0)\n","        t.sort()#sort on the basis of time\n","\n","        h=0\n","        amp = np.zeros(len(t))\n","        res = np.zeros(len(t)-1)\n","        for l in range(len(t)):\n","            amp[l]=i[t[l]]\n","           \n","        \n","        amp_diff = first_diff(amp)\n","        \n","        t_diff = first_diff(t)\n","        \n","        for q in range(len(amp_diff)):\n","            res[q] = amp_diff[q]/t_diff[q]         \n","        output[k] = np.mean(res) \n","        k=k+1\n","    return np.sum(output)/14\n","\n","\n","\n","\n","def first_diff(i):\n","    b=i\n","    \n","    \n","    out = np.zeros(len(b))\n","    \n","    for j in range(len(i)):\n","        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n","        \n","        j=j+1\n","        c=out[1:len(out)]\n","    return c #returns first diff\n","\n","\n","def slope_var(p):\n","    b = p #Extracting the data from the 14 channels\n","    output = np.zeros(len(b)) #Initializing the output array with zeros\n","    res = np.zeros(len(b)-1)\n","    \n","    k = 0; #For counting the current row no.\n","    for i in b:\n","        x=i\n","        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n","        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n","        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n","        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n","        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n","        t.sort() #sorting according to time\n","\n","        h=0\n","        amp = np.zeros(len(t))\n","        res = np.zeros(len(t)-1)\n","        for l in range(len(t)):\n","            amp[l]=i[t[l]]\n","           \n","        \n","        amp_diff = first_diff(amp)\n","        \n","        t_diff = first_diff(t)\n","        \n","        for q in range(len(amp_diff)):\n","            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n","    \n","        output[k] = np.var(res) \n","        k=k+1#counting k\n","    return np.sum(output)/14\n","\n","def wrapper3(epoch):\n","    var1 = slope_mean(epoch)\n","    var2 = slope_var(epoch)\n","    return var1,var2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpo-bR-QhS7b","colab_type":"code","colab":{}},"source":["from scipy import signal\n","\n","def maxPwelch(data_win,Fs):\n"," \n","    \n","    BandF = [0.1, 3, 7, 12, 30]\n","    PMax = np.zeros([14,(len(BandF)-1)]);\n","    \n","    for j in range(14):\n","        f,Psd = signal.welch(data_win[j,:], Fs)\n","        \n","        for i in range(len(BandF)-1):\n","            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n","            PMax[j,i] = np.max(Psd[fr])\n","    \n","    return np.sum(PMax[:,0])/14,np.sum(PMax[:,1])/14,np.sum(PMax[:,2])/14,np.sum(PMax[:,3])/14"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-Zc4Oxmha20","colab_type":"code","colab":{}},"source":["def entropy(labels): # Shanon Entropy\n","    \"\"\" Computes entropy of 0-1 vector. \"\"\"\n","    n_labels = len(labels)\n","    counts = np.bincount(labels)\n","    probs = counts[np.nonzero(counts)] / n_labels\n","    n_classes = len(probs)\n","\n","    if n_classes <= 1:\n","        return 0\n","    return - np.sum(probs * np.log(probs)) / np.log(n_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmDxrYrJhkqe","colab_type":"code","colab":{}},"source":["def autogressiveModelParameters(labels):\n","    b_labels = len(labels)\n","    feature = []\n","    for i in range(14):\n","        coeff, sig = alg.AR_est_YW(labels[i,:], 11,)\n","        feature.append(coeff)\n","    a = []     \n","    for i in range(11):\n","        a.append(np.sum(feature[:][i])/14)\n","     \n","    return a"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qzz3XmKuhoQd","colab_type":"code","colab":{}},"source":["def autogressiveModelParametersBurg(labels):\n","    feature = []\n","    feature1 = []\n","    model_order = 3\n","    for i in range(14):\n","        AR, rho, ref = arburg(labels[i], model_order)\n","        feature.append(AR);\n","    for j in range(14):\n","        for i in range(model_order):\n","            feature1.append(feature[j][i])\n","\n","    return feature1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjbvHaZdhtWY","colab_type":"code","colab":{}},"source":["lowfiles  = [f for f in listdir('/content/drive/My Drive/Colab Notebooks/Training-Data/Low') if isfile(join('/content/drive/My Drive/Colab NotebooksTraining-Data/Low', f))] \n","highfiles = [f for f in listdir('/content/drive/My Drive/Colab Notebooks/Training-Data/High') if isfile(join('/content/drive/My Drive/Colab NotebooksTraining-Data/High', f))]\n","files = []\n","\n","for i in lowfiles:\n","    files.append([i,'/content/drive/My Drive/Colab Notebooks/Training-Data/Low'])\n","    \n","for i in highfiles:\n","    files.append([i,'/content/drive/My Drive/Colab Notebooks/Training-Data/High'])\n","    \n","mypath = '/content/drive/My Drive/Colab Notebooks/Training-Data/'\n","csvfile = \"/content/drive/My Drive/Colab Notebooks/Features/features.csv\"\n","\n","with open(csvfile, \"a\") as output:\n","    writer = csv.writer(output, lineterminator='\\n')\n","    writer.writerow(names) \n","    for counter in range(len(files)):\n","        subfolder =  files[counter][1]\n","        tag = files[counter][1] \n","        data_path = mypath + subfolder +'/'+files[counter][0]\n","        f = pyedflib.EdfReader(data_path)\n","        n = f.signals_in_file\n","        signal_labels = f.getSignalLabels()\n","        sigbufs = np.zeros((14, f.getNSamples()[3]))\n","        for i in np.arange(14):\n","            sigbufs[i,:] = f.readSignal(i+2)\n","        for i in np.arange(5,185,3):\n","            features = []\n","            epoch = sigbufs[:,i*128:(i+3)*128]\n","            if len(epoch[0]) == 0:\n","                break\n","            \n","            # Hjorth Parameters\n","            feature_list = hjorth(epoch)\n","            for feat in feature_list:\n","                features.append(feat)\n","        \n","            #Kurtosis , 2nd Diff Mean, 2nd Diff Max\n","            feature_list = wrapper1(epoch)\n","            for feat in feature_list:\n","                features.append(feat)\n","            \n","            #Coeffeicient of Variation\n","            feat = coeff_var(epoch)\n","            features.append(feat)\n","            \n","            #Skewness , 1st Difference Mean, 1st Difference Max\n","            feature_list = wrapper2(epoch)\n","            for feat in feature_list:\n","                features.append(feat)\n","            \n","            \n","            # wavelet transform features \n","            feature_list = wavelet_features(epoch)\n","            for feat in feature_list:\n","                features.append(feat)\n","        \n","        \n","            # Variance and mean of Vertex to Vertex Slope\n","            feature_list = wrapper3(epoch)\n","            for feat in feature_list:\n","                features.append(feat)\n","            \n","            \n","            #Fast Fourier Transform features(Max Power)\n","            feature_list  =  maxPwelch(epoch,128)\n","            for feat in feature_list:\n","                features.append(feat)\n","        \n","            #Autoregressive model Coefficients\n","            feature_list = autogressiveModelParametersBurg(epoch)\n","            for feat in feature_list:\n","                features.append(feat.real)\n","            \n","            features.append(tag);\n","        \n","            writer.writerow(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8X7lrHnh8ym","colab_type":"code","colab":{}},"source":["r = csv.reader(open('/content/drive/My Drive/Colab Notebooks/Features/features.csv')) # Here your csv file\n","lines = [l for l in r]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OU9NB5TiBeX","colab_type":"code","outputId":"3fca226e-4dd3-4d9b-dcd1-5804907f8d93","executionInfo":{"status":"ok","timestamp":1591527633286,"user_tz":-330,"elapsed":821,"user":{"displayName":"KALAIVAANI.N 17ITR044","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT4gRR1EY4A_sDZGIzhjevh0x4aHOTd0MEwE4M=s64","userId":"06629915513144874112"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["for i in range(len(lines[1])-1):  \n","    columns = []\n","    for j in range(1,len(lines)):\n","        try:\n","            columns.append(float(lines[j][i]))\n","        except ValueError:\n","            break\n","\n","    mean = np.mean(columns,axis = 0)\n","    std_dev  = np.std(columns,axis = 0)\n","    \n","    for j in range(1,len(lines)):\n","        try:\n","           lines[j][i] = (float(lines[j][i])-mean)/std_dev\n","        except ValueError:\n","           break\n","\n","writer = csv.writer(open('/content/drive/My Drive/Colab Notebooks/Features/Normalizedfeatures.csv', 'w')) # This file will store the normalized features\n","writer.writerows(lines)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  keepdims=keepdims)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n","  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"}]}]}